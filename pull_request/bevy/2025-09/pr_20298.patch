diff --git a/crates/bevy_app/src/app.rs b/crates/bevy_app/src/app.rs
index 5e0021afe43ce..789debfac3578 100644
--- a/crates/bevy_app/src/app.rs
+++ b/crates/bevy_app/src/app.rs
@@ -15,7 +15,10 @@ use bevy_ecs::{
     intern::Interned,
     message::{message_update_system, MessageCursor},
     prelude::*,
-    schedule::{InternedSystemSet, ScheduleBuildSettings, ScheduleLabel},
+    schedule::{
+        InternedSystemSet, ScheduleBuildSettings, ScheduleCleanupPolicy, ScheduleError,
+        ScheduleLabel,
+    },
     system::{IntoObserverSystem, ScheduleSystem, SystemId, SystemInput},
 };
 use bevy_platform::collections::HashMap;
@@ -325,6 +328,38 @@ impl App {
         self
     }
 
+    /// Removes all systems in a [`SystemSet`]. This will cause the schedule to be rebuilt when
+    /// the schedule is run again and can be slow. A [`ScheduleError`] is returned if the schedule needs to be
+    /// [`Schedule::initialize`]'d or the `set` is not found.
+    ///
+    /// Note that this can remove all systems of a type if you pass
+    /// the system to this function as systems implicitly create a set based
+    /// on the system type.
+    ///
+    /// ## Example
+    /// ```
+    /// # use bevy_app::prelude::*;
+    /// # use bevy_ecs::schedule::ScheduleCleanupPolicy;
+    /// #
+    /// # let mut app = App::new();
+    /// # fn system_a() {}
+    /// # fn system_b() {}
+    /// #
+    /// // add the system
+    /// app.add_systems(Update, system_a);
+    ///
+    /// // remove the system
+    /// app.remove_systems_in_set(Update, system_a, ScheduleCleanupPolicy::RemoveSystemsOnly);
+    /// ```
+    pub fn remove_systems_in_set<M>(
+        &mut self,
+        schedule: impl ScheduleLabel,
+        set: impl IntoSystemSet<M>,
+        policy: ScheduleCleanupPolicy,
+    ) -> Result<usize, ScheduleError> {
+        self.main_mut().remove_systems_in_set(schedule, set, policy)
+    }
+
     /// Registers a system and returns a [`SystemId`] so it can later be called by [`World::run_system`].
     ///
     /// It's possible to register the same systems more than once, they'll be stored separately.
diff --git a/crates/bevy_app/src/sub_app.rs b/crates/bevy_app/src/sub_app.rs
index 84d9ef9610be4..c344caa81c364 100644
--- a/crates/bevy_app/src/sub_app.rs
+++ b/crates/bevy_app/src/sub_app.rs
@@ -3,7 +3,10 @@ use alloc::{boxed::Box, string::String, vec::Vec};
 use bevy_ecs::{
     message::MessageRegistry,
     prelude::*,
-    schedule::{InternedScheduleLabel, InternedSystemSet, ScheduleBuildSettings, ScheduleLabel},
+    schedule::{
+        InternedScheduleLabel, InternedSystemSet, ScheduleBuildSettings, ScheduleCleanupPolicy,
+        ScheduleError, ScheduleLabel,
+    },
     system::{ScheduleSystem, SystemId, SystemInput},
 };
 use bevy_platform::collections::{HashMap, HashSet};
@@ -219,6 +222,18 @@ impl SubApp {
         self
     }
 
+    /// See [`App::remove_systems_in_set`]
+    pub fn remove_systems_in_set<M>(
+        &mut self,
+        schedule: impl ScheduleLabel,
+        set: impl IntoSystemSet<M>,
+        policy: ScheduleCleanupPolicy,
+    ) -> Result<usize, ScheduleError> {
+        self.world.schedule_scope(schedule, |world, schedule| {
+            schedule.remove_systems_in_set(set, world, policy)
+        })
+    }
+
     /// See [`App::register_system`].
     pub fn register_system<I, O, M>(
         &mut self,
diff --git a/crates/bevy_ecs/src/schedule/error.rs b/crates/bevy_ecs/src/schedule/error.rs
index ec008e9c3fa69..caa34a1d40a6a 100644
--- a/crates/bevy_ecs/src/schedule/error.rs
+++ b/crates/bevy_ecs/src/schedule/error.rs
@@ -259,3 +259,26 @@ impl ScheduleBuildWarning {
         }
     }
 }
+
+/// Error returned from some `Schedule` methods
+#[derive(Error, Debug)]
+pub enum ScheduleError {
+    /// Operation cannot be completed because the schedule has changed and `Schedule::initialize` needs to be called
+    #[error("Operation cannot be completed because the schedule has changed and `Schedule::initialize` needs to be called")]
+    Uninitialized,
+    /// Method could not find set
+    #[error("Set not found")]
+    SetNotFound,
+    /// Schedule not found
+    #[error("Schedule not found.")]
+    ScheduleNotFound,
+    /// Error initializing schedule
+    #[error("{0}")]
+    ScheduleBuildError(ScheduleBuildError),
+}
+
+impl From<ScheduleBuildError> for ScheduleError {
+    fn from(value: ScheduleBuildError) -> Self {
+        Self::ScheduleBuildError(value)
+    }
+}
diff --git a/crates/bevy_ecs/src/schedule/node.rs b/crates/bevy_ecs/src/schedule/node.rs
index cf235f655af3a..6f07c321e07a7 100644
--- a/crates/bevy_ecs/src/schedule/node.rs
+++ b/crates/bevy_ecs/src/schedule/node.rs
@@ -487,14 +487,10 @@ impl Systems {
         self.nodes.get_mut(key).and_then(|node| node.get_mut())
     }
 
-    /// Returns a mutable reference to the system with the given key, panicking
-    /// if it does not exist.
-    ///
-    /// # Panics
-    ///
-    /// If the system with the given key does not exist in this container.
-    pub(crate) fn node_mut(&mut self, key: SystemKey) -> &mut SystemNode {
-        &mut self.nodes[key]
+    /// Returns a mutable reference to the system with the given key. Will return
+    /// `None` if the key does not exist.
+    pub(crate) fn node_mut(&mut self, key: SystemKey) -> Option<&mut SystemNode> {
+        self.nodes.get_mut(key)
     }
 
     /// Returns `true` if the system with the given key has conditions.
@@ -554,6 +550,25 @@ impl Systems {
         key
     }
 
+    /// Remove a system with [`SystemKey`]
+    pub(crate) fn remove(&mut self, key: SystemKey) -> bool {
+        let mut found = false;
+        if self.nodes.remove(key).is_some() {
+            found = true;
+        }
+
+        if self.conditions.remove(key).is_some() {
+            found = true;
+        }
+
+        if let Some(index) = self.uninit.iter().position(|value| *value == key) {
+            self.uninit.remove(index);
+            found = true;
+        }
+
+        found
+    }
+
     /// Returns `true` if all systems in this container have been initialized.
     pub fn is_initialized(&self) -> bool {
         self.uninit.is_empty()
@@ -646,6 +661,11 @@ impl SystemSets {
         self.sets.get(key).map(|set| &**set)
     }
 
+    /// Returns the key for the given system set, returns None if it does not exist.
+    pub fn get_key(&self, set: InternedSystemSet) -> Option<SystemSetKey> {
+        self.ids.get(&set).copied()
+    }
+
     /// Returns the key for the given system set, inserting it into this
     /// container if it does not already exist.
     pub fn get_key_or_insert(&mut self, set: InternedSystemSet) -> SystemSetKey {
@@ -716,6 +736,14 @@ impl SystemSets {
         key
     }
 
+    /// Remove a set with a [`SystemSetKey`]
+    pub(crate) fn remove(&mut self, key: SystemSetKey) -> bool {
+        self.sets.remove(key);
+        self.conditions.remove(key);
+        self.uninit.retain(|uninit| uninit.key != key);
+        true
+    }
+
     /// Returns `true` if all system sets' conditions in this container have
     /// been initialized.
     pub fn is_initialized(&self) -> bool {
diff --git a/crates/bevy_ecs/src/schedule/schedule.rs b/crates/bevy_ecs/src/schedule/schedule.rs
index 876a53a45c29d..87a91c86ae568 100644
--- a/crates/bevy_ecs/src/schedule/schedule.rs
+++ b/crates/bevy_ecs/src/schedule/schedule.rs
@@ -179,6 +179,21 @@ impl Schedules {
         self
     }
 
+    /// Removes all systems in a [`SystemSet`]. This will cause the schedule to be rebuilt when
+    /// the schedule is run again. A [`ScheduleError`] is returned if the schedule needs to be
+    /// [`Schedule::initialize`]'d or the `set` is not found.
+    pub fn remove_systems_in_set<M>(
+        &mut self,
+        schedule: impl ScheduleLabel,
+        set: impl IntoSystemSet<M>,
+        world: &mut World,
+        policy: ScheduleCleanupPolicy,
+    ) -> Result<usize, ScheduleError> {
+        self.get_mut(schedule)
+            .ok_or(ScheduleError::ScheduleNotFound)?
+            .remove_systems_in_set(set, world, policy)
+    }
+
     /// Configures a collection of system sets in the provided schedule, adding any sets that do not exist.
     #[track_caller]
     pub fn configure_sets<M>(
@@ -377,6 +392,41 @@ impl Schedule {
         self
     }
 
+    /// Removes all systems in a [`SystemSet`]. This will cause the schedule to be rebuilt when
+    /// the schedule is run again. A [`ScheduleError`] is returned if the schedule needs to be
+    /// [`Schedule::initialize`]'d or the `set` is not found.
+    ///
+    /// Note that this can remove all systems of a type if you pass
+    /// the system to this function as systems implicitly create a set based
+    /// on the system type.
+    ///
+    /// ## Example
+    /// ```
+    /// # use bevy_ecs::prelude::*;
+    /// # use bevy_ecs::schedule::ScheduleCleanupPolicy;
+    /// #
+    /// # fn my_system() {}
+    /// #
+    /// let mut schedule = Schedule::default();
+    /// // add the system to the schedule
+    /// schedule.add_systems(my_system);
+    /// let mut world = World::default();
+    ///
+    /// // remove the system
+    /// schedule.remove_systems_in_set(my_system, &mut world, ScheduleCleanupPolicy::RemoveSystemsOnly);
+    /// ```
+    pub fn remove_systems_in_set<M>(
+        &mut self,
+        set: impl IntoSystemSet<M>,
+        world: &mut World,
+        policy: ScheduleCleanupPolicy,
+    ) -> Result<usize, ScheduleError> {
+        if self.graph.changed {
+            self.initialize(world)?;
+        }
+        self.graph.remove_systems_in_set(set, policy)
+    }
+
     /// Suppress warnings and errors that would result from systems in these sets having ambiguities
     /// (conflicting access but indeterminate order) with systems in `set`.
     #[track_caller]
@@ -677,6 +727,8 @@ pub struct ScheduleGraph {
     hierarchy: Dag<NodeId>,
     /// Directed acyclic graph of the dependency (which systems/sets have to run before which other systems/sets)
     dependency: Dag<NodeId>,
+    /// Map of systems in each set
+    set_systems: HashMap<SystemSetKey, Vec<SystemKey>>,
     ambiguous_with: UnGraph<NodeId>,
     /// Nodes that are allowed to have ambiguous ordering relationship with any other systems.
     pub ambiguous_with_all: HashSet<NodeId>,
@@ -695,6 +747,7 @@ impl ScheduleGraph {
             system_sets: SystemSets::default(),
             hierarchy: Dag::new(),
             dependency: Dag::new(),
+            set_systems: HashMap::new(),
             ambiguous_with: UnGraph::default(),
             ambiguous_with_all: HashSet::default(),
             conflicting_systems: Vec::new(),
@@ -893,6 +946,146 @@ impl ScheduleGraph {
         AnonymousSet::new(id)
     }
 
+    /// Returns a `Vec` containing all [`SystemKey`]s in a [`SystemSet`].
+    ///
+    /// # Errors
+    ///
+    /// This method may return an error. It'll be:
+    ///
+    /// - `ScheduleError::Uninitialized` if the schedule has been changed,
+    ///   and `Self::initialize` has not been called.
+    /// - `ScheduleError::NotFound` if `system_set` isn't present in the
+    ///   schedule.
+    pub fn systems_in_set(
+        &self,
+        system_set: InternedSystemSet,
+    ) -> Result<&[SystemKey], ScheduleError> {
+        if self.changed {
+            return Err(ScheduleError::Uninitialized);
+        }
+        let system_set_id = self
+            .system_sets
+            .get_key(system_set)
+            .ok_or(ScheduleError::SetNotFound)?;
+        self.set_systems
+            .get(&system_set_id)
+            .map(Vec::as_slice)
+            .ok_or(ScheduleError::SetNotFound)
+    }
+
+    fn add_edges_for_transitive_dependencies(&mut self, node: NodeId) {
+        let in_nodes: Vec<_> = self
+            .hierarchy
+            .graph
+            .neighbors_directed(node, Incoming)
+            .collect();
+        let out_nodes: Vec<_> = self
+            .hierarchy
+            .graph
+            .neighbors_directed(node, Outgoing)
+            .collect();
+
+        for &in_node in &in_nodes {
+            for &out_node in &out_nodes {
+                self.hierarchy.graph.add_edge(in_node, out_node);
+            }
+        }
+
+        let in_nodes: Vec<_> = self
+            .dependency
+            .graph
+            .neighbors_directed(node, Incoming)
+            .collect();
+        let out_nodes: Vec<_> = self
+            .dependency
+            .graph
+            .neighbors_directed(node, Outgoing)
+            .collect();
+
+        for &in_node in &in_nodes {
+            for &out_node in &out_nodes {
+                self.dependency.graph.add_edge(in_node, out_node);
+            }
+        }
+    }
+
+    /// Remove all systems in a set and any dependencies on those systems and set.
+    pub fn remove_systems_in_set<M>(
+        &mut self,
+        system_set: impl IntoSystemSet<M>,
+        policy: ScheduleCleanupPolicy,
+    ) -> Result<usize, ScheduleError> {
+        let set = system_set.into_system_set();
+        let interned = set.intern();
+        // clone the keys out of the schedule as the systems are getting removed from self
+        let keys = self.systems_in_set(interned)?.to_vec();
+
+        self.changed = true;
+
+        match policy {
+            ScheduleCleanupPolicy::RemoveSetAndSystemsAllowBreakages => {
+                let Some(set_key) = self.system_sets.get_key(interned) else {
+                    return Err(ScheduleError::SetNotFound);
+                };
+
+                self.remove_systems_by_keys(&keys);
+                self.remove_set_by_key(set_key);
+
+                Ok(keys.len())
+            }
+            ScheduleCleanupPolicy::RemoveSystemsOnlyAllowBreakages => {
+                self.remove_systems_by_keys(&keys);
+
+                Ok(keys.len())
+            }
+            ScheduleCleanupPolicy::RemoveSetAndSystems => {
+                let Some(set_key) = self.system_sets.get_key(interned) else {
+                    return Err(ScheduleError::SetNotFound);
+                };
+
+                for &key in &keys {
+                    self.add_edges_for_transitive_dependencies(key.into());
+                }
+
+                self.add_edges_for_transitive_dependencies(set_key.into());
+
+                self.remove_systems_by_keys(&keys);
+                self.remove_set_by_key(set_key);
+
+                Ok(keys.len())
+            }
+            ScheduleCleanupPolicy::RemoveSystemsOnly => {
+                for &key in &keys {
+                    self.add_edges_for_transitive_dependencies(key.into());
+                }
+
+                self.remove_systems_by_keys(&keys);
+
+                Ok(keys.len())
+            }
+        }
+    }
+
+    fn remove_systems_by_keys(&mut self, keys: &[SystemKey]) {
+        for &key in keys {
+            self.systems.remove(key);
+
+            self.hierarchy.graph.remove_node(key.into());
+            self.dependency.graph.remove_node(key.into());
+            self.ambiguous_with.remove_node(key.into());
+            self.ambiguous_with_all.remove(&NodeId::from(key));
+        }
+    }
+
+    fn remove_set_by_key(&mut self, key: SystemSetKey) {
+        self.system_sets.remove(key);
+        self.set_systems.remove(&key);
+        self.hierarchy.graph.remove_node(key.into());
+        self.dependency.graph.remove_node(key.into());
+        self.ambiguous_with.remove_node(key.into());
+        self.ambiguous_with_all.remove(&NodeId::from(key));
+    }
+
     /// Update the internal graphs (hierarchy, dependency, ambiguity) by adding a single [`GraphInfo`]
     fn update_graphs(&mut self, id: NodeId, graph_info: GraphInfo) {
         self.changed = true;
@@ -1030,6 +1223,7 @@ impl ScheduleGraph {
 
         // flatten: combine `in_set` with `ambiguous_with` information
         let ambiguous_with_flattened = self.get_ambiguous_with_flattened(&set_systems);
+        self.set_systems = set_systems;
 
         // check for conflicts
         let conflicting_systems = self.get_conflicting_systems(
@@ -1345,8 +1539,13 @@ impl ScheduleGraph {
             .zip(schedule.systems.drain(..))
             .zip(schedule.system_conditions.drain(..))
         {
-            self.systems.node_mut(key).inner = Some(system);
-            *self.systems.get_conditions_mut(key).unwrap() = conditions;
+            if let Some(node) = self.systems.node_mut(key) {
+                node.inner = Some(system);
+            }
+
+            if let Some(node_conditions) = self.systems.get_conditions_mut(key) {
+                *node_conditions = conditions;
+            }
         }
 
         for (key, conditions) in schedule
@@ -1354,7 +1553,9 @@ impl ScheduleGraph {
             .drain(..)
             .zip(schedule.set_conditions.drain(..))
         {
-            *self.system_sets.get_conditions_mut(key).unwrap() = conditions;
+            if let Some(node_conditions) = self.system_sets.get_conditions_mut(key) {
+                *node_conditions = conditions;
+            }
         }
 
         let (new_schedule, warnings) = self.build_schedule(world, ignored_ambiguities)?;
@@ -1370,7 +1571,7 @@ impl ScheduleGraph {
 
         // move systems into new schedule
         for &key in &schedule.system_ids {
-            let system = self.systems.node_mut(key).inner.take().unwrap();
+            let system = self.systems.node_mut(key).unwrap().inner.take().unwrap();
             let conditions = core::mem::take(self.systems.get_conditions_mut(key).unwrap());
             schedule.systems.push(system);
             schedule.system_conditions.push(conditions);
@@ -1422,6 +1623,30 @@ pub enum ReportCycles {
     Dependency,
 }
 
+/// Policy to use when removing systems.
+#[derive(Default)]
+pub enum ScheduleCleanupPolicy {
+    /// Remove the referenced set and any systems in the set.
+    /// Attempts to maintain the order between the transitive dependencies by adding new edges
+    /// between the existing before and after dependencies on the set and the systems.
+    /// This does not remove sets that might sub sets of the set.
+    #[default]
+    RemoveSetAndSystems,
+    /// Remove only the systems in the set. The set
+    /// Attempts to maintain the order between the transitive dependencies by adding new edges
+    /// between the existing before and after dependencies on the systems.
+    RemoveSystemsOnly,
+    /// Remove the set and any systems in the set.
+    /// Note that this will not add new edges and
+    /// so will break any transitive dependencies on that set or systems.
+    /// This does not remove sets that might sub sets of the set.
+    RemoveSetAndSystemsAllowBreakages,
+    /// Remove only the systems in the set.
+    /// Note that this will not add new edges and
+    /// so will break any transitive dependencies on that set or systems.
+    RemoveSystemsOnlyAllowBreakages,
+}
+
 // methods for reporting errors
 impl ScheduleGraph {
     /// Returns the name of the node with the given [`NodeId`]. Resolves
@@ -1769,9 +1994,10 @@ mod tests {
 
     use crate::{
         error::{ignore, panic, DefaultErrorHandler, Result},
-        prelude::{ApplyDeferred, Res, Resource},
+        prelude::{ApplyDeferred, IntoSystemSet, Res, Resource},
         schedule::{
-            tests::ResMut, IntoScheduleConfigs, Schedule, ScheduleBuildSettings, SystemSet,
+            tests::ResMut, IntoScheduleConfigs, Schedule, ScheduleBuildSettings,
+            ScheduleCleanupPolicy, SystemSet,
         },
         system::Commands,
         world::World,
@@ -2586,4 +2812,167 @@ mod tests {
         );
         schedule.run(&mut world);
     }
+
+    #[test]
+    fn get_a_system_key() {
+        fn test_system() {}
+
+        let mut schedule = Schedule::default();
+        schedule.add_systems(test_system);
+        let mut world = World::default();
+        let _ = schedule.initialize(&mut world);
+
+        let keys = schedule
+            .graph()
+            .systems_in_set(test_system.into_system_set().intern())
+            .unwrap();
+        assert_eq!(keys.len(), 1);
+    }
+
+    #[test]
+    fn get_system_keys_in_set() {
+        fn system_1() {}
+        fn system_2() {}
+
+        let mut schedule = Schedule::default();
+        schedule.add_systems((system_1, system_2).in_set(TestSet::First));
+        let mut world = World::default();
+        let _ = schedule.initialize(&mut world);
+
+        let keys = schedule
+            .graph()
+            .systems_in_set(TestSet::First.into_system_set().intern())
+            .unwrap();
+        assert_eq!(keys.len(), 2);
+    }
+
+    #[test]
+    fn get_system_keys_with_same_name() {
+        fn test_system() {}
+
+        let mut schedule = Schedule::default();
+        schedule.add_systems((test_system, test_system));
+        let mut world = World::default();
+        let _ = schedule.initialize(&mut world);
+
+        let keys = schedule
+            .graph()
+            .systems_in_set(test_system.into_system_set().intern())
+            .unwrap();
+        assert_ne!(keys[0], keys[1]);
+    }
+
+    #[test]
+    fn remove_a_system() {
+        fn system() {}
+
+        let mut schedule = Schedule::default();
+        schedule.add_systems(system);
+        let mut world = World::default();
+
+        let remove_count = schedule.remove_systems_in_set(
+            system,
+            &mut world,
+            ScheduleCleanupPolicy::RemoveSetAndSystemsAllowBreakages,
+        );
+        assert_eq!(remove_count.unwrap(), 1);
+
+        // schedule has changed, so we check initializing again
+        schedule.initialize(&mut world).unwrap();
+        assert_eq!(schedule.graph().systems.len(), 0);
+    }
+
+    #[test]
+    fn remove_multiple_systems() {
+        fn system() {}
+
+        let mut schedule = Schedule::default();
+        schedule.add_systems((system, system));
+        let mut world = World::default();
+
+        let remove_count = schedule.remove_systems_in_set(
+            system,
+            &mut world,
+            ScheduleCleanupPolicy::RemoveSetAndSystemsAllowBreakages,
+        );
+        assert_eq!(remove_count.unwrap(), 2);
+
+        // schedule has changed, so we check initializing again
+        schedule.initialize(&mut world).unwrap();
+        assert_eq!(schedule.graph().systems.len(), 0);
+    }
+
+    #[test]
+    fn remove_a_system_with_dependencies() {
+        fn system_1() {}
+        fn system_2() {}
+
+        let mut schedule = Schedule::default();
+        schedule.add_systems((system_1, system_2).chain());
+        let mut world = World::default();
+
+        let remove_count = schedule.remove_systems_in_set(
+            system_1,
+            &mut world,
+            ScheduleCleanupPolicy::RemoveSetAndSystemsAllowBreakages,
+        );
+        assert_eq!(remove_count.unwrap(), 1);
+
+        // schedule has changed, so we check initializing again
+        schedule.initialize(&mut world).unwrap();
+        assert_eq!(schedule.graph().systems.len(), 1);
+    }
+
+    #[test]
+    fn remove_a_system_and_still_ordered() {
+        #[derive(Resource)]
+        struct A;
+
+        fn system_1(_: ResMut<A>) {}
+        fn system_2() {}
+        fn system_3(_: ResMut<A>) {}
+
+        let mut schedule = Schedule::default();
+        schedule.add_systems((system_1, system_2, system_3).chain());
+        let mut world = World::new();
+
+        let _ = schedule.remove_systems_in_set(
+            system_2,
+            &mut world,
+            ScheduleCleanupPolicy::RemoveSetAndSystems,
+        );
+
+        let result = schedule.initialize(&mut world);
+        assert!(result.is_ok());
+        let conflicts = schedule.graph().conflicting_systems();
+        assert!(conflicts.is_empty());
+    }
+
+    #[test]
+    fn remove_a_set_and_still_ordered() {
+        #[derive(Resource)]
+        struct A;
+
+        #[derive(SystemSet, Hash, PartialEq, Eq, Clone, Debug)]
+        struct B;
+
+        fn system_1(_: ResMut<A>) {}
+        fn system_2() {}
+        fn system_3(_: ResMut<A>) {}
+
+        let mut schedule = Schedule::default();
+        schedule.add_systems((system_1.before(B), system_2, system_3.after(B)));
+        let mut world = World::new();
+
+        let _ = schedule.remove_systems_in_set(
+            B,
+            &mut world,
+            ScheduleCleanupPolicy::RemoveSetAndSystems,
+        );
+
+        let result = schedule.initialize(&mut world);
+        assert!(result.is_ok());
+        let conflicts = schedule.graph().conflicting_systems();
+        assert!(conflicts.is_empty());
+    }
 }
diff --git a/release-content/release-notes/remove_systems.md b/release-content/release-notes/remove_systems.md
new file mode 100644
index 0000000000000..ac1c81a58b09a
--- /dev/null
+++ b/release-content/release-notes/remove_systems.md
@@ -0,0 +1,22 @@
+---
+title: Remove Systems from Schedules
+authors: ["@hymm"]
+pull_requests: [20298]
+---
+
+A long requested feature has come to Bevy! You can now remove systems from a schedule.
+The previous recommended way of preventing a scheduled system from running was to use `RunCondition`'s.
+You will still use this for most situations as removing a system will cause the schedule to be rebuilt.
+This process can be slow since the schedule checking logic is complex. But in situations where this is
+not a problem, you can now call `remove_systems_in_set`. The advantage of this is that this will remove the
+cost of the run condition being checked.
+
+```rust
+app.add_systems((system_a, (system_b, system_c).in_set(MySet)));
+
+// remove a system
+schedule.remove_systems_in_set(my_system, ScheduleCleanupPolicy::RemoveSystemsOnly);
+
+// remove systems in a set
+app.remove_systems_in_set(MySet, ScheduleCleanupPolicy::RemoveSetAndSystems);
+```
