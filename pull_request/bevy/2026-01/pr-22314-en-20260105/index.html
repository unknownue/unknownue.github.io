<!doctype html><html class="dark light" lang=en><head><meta charset=UTF-8><meta content="IE=edge" http-equiv=X-UA-Compatible><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content=https://unknownue.github.io name=base><title>
         #22314 Parallel GPU buffer writes
        
    </title><meta content="#22314 Parallel GPU buffer writes" property=og:title><meta content="A personal blog built with Zola and Apollo theme" property=og:description><meta content="A personal blog built with Zola and Apollo theme" name=description><link href=/icons/favicon.png rel=icon type=image/png><link href=https://unknownue.github.io/fonts.css rel=stylesheet><script src=https://unknownue.github.io/js/codeblock.js></script><script src=https://unknownue.github.io/js/toc.js></script><script src=https://unknownue.github.io/js/note.js></script><script>MathJax = {
              tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
              }
            };</script><script async id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link title="Unknownue's Blog" href=https://unknownue.github.io/atom.xml rel=alternate type=application/atom+xml><link href=https://unknownue.github.io/theme/light.css rel=stylesheet><link href=https://unknownue.github.io/theme/dark.css id=darkModeStyle rel=stylesheet><script src=https://unknownue.github.io/js/themetoggle.js></script><script>setTheme(getSavedTheme());</script><link href=https://unknownue.github.io/main.css media=screen rel=stylesheet><script src=https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js></script><script>// Initialize mermaid once DOM is loaded
        document.addEventListener('DOMContentLoaded', function() {
            mermaid.initialize({
                startOnLoad: false,
                theme: document.body && document.body.classList.contains('dark') ? 'dark' : 'default',
                securityLevel: 'loose',
                flowchart: {
                    useMaxWidth: true,
                    htmlLabels: true
                },
                sequence: {
                    diagramMarginX: 50,
                    diagramMarginY: 10,
                    actorMargin: 50,
                    width: 150,
                    height: 65
                }
            });
        });</script><script src=https://unknownue.github.io/js/main.js></script><script defer src=https://unknownue.github.io/js/label-colors.js></script><link href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/github.min.css rel=stylesheet><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/rust.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/python.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/javascript.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/typescript.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/go.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/languages/cpp.min.js></script><script>// Ensure highlight.js is properly configured
        document.addEventListener('DOMContentLoaded', function() {
            if (typeof hljs !== 'undefined') {
                hljs.configure({
                    languages: ['rust', 'javascript', 'python', 'cpp', 'go', 'typescript'],
                    ignoreUnescapedHTML: true
                });
                console.log('Highlight.js configured in header');
            }
        });</script><link href=https://cdn.jsdelivr.net/npm/diff2html/bundles/css/diff2html.min.css rel=stylesheet><script src=https://cdn.jsdelivr.net/npm/diff2html/bundles/js/diff2html-ui.min.js></script><script src=https://unknownue.github.io/js/syntax-highlight.js></script><script src=https://unknownue.github.io/js/diff-sidebar.js></script><script src="https://unknownue.github.io/js/searchElasticlunr.min.js?h=3626c0ef99daa745b31e" defer></script><body><div class=content><header><div class=main><a href=https://unknownue.github.io>Unknownue's Blog</a><div class=socials><a class=social href=https://github.com/unknownue rel=me> <img alt=github src=https://unknownue.github.io/icons/social/github.svg> </a><a class=social href=https://github.com/unknownue/unknownue.github.io rel=me> <img alt=github-io src=https://unknownue.github.io/icons/social/rss.svg> </a></div></div><nav><a href=https://unknownue.github.io/posts style=margin-left:.25em>/posts</a><a href=https://unknownue.github.io/projects style=margin-left:.25em>/projects</a><a href=https://unknownue.github.io/about style=margin-left:.25em>/about</a><a href=https://unknownue.github.io/tags style=margin-left:.25em>/tags</a><button title="$SHORTCUT to open search" class=search-button id=search-button><img alt=Search class=search-icon src=https://unknownue.github.io/icons/search.svg></button><div class="search-modal js" aria-labelledby=modalTitle id=searchModal role=dialog><div id=modal-content><h1 class=page-header id=modalTitle>Search</h1><div id=searchBar><input aria-controls=results-container aria-expanded=false autocomplete=off id=searchInput placeholder=Search... role=combobox spellcheck=false><button title="Clear search" class=clear-button id=clear-search><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="m256-200-56-56 224-224-224-224 56-56 224 224 224-224 56 56-224 224 224 224-56 56-224-224-224 224Z"/></svg></button></div><div id=results-container><div id=results-info><span id=zero_results style=display:none>No results</span><span id=one_result style=display:none>1 result</span><span id=many_results style=display:none>$NUMBER results</span></div><div id=results role=listbox></div></div></div></div><a onclick="toggleTheme(); event.preventDefault();" href=# id=dark-mode-toggle> <img alt=Light id=sun-icon src=https://unknownue.github.io/icons/sun.svg style=filter:invert()> <img alt=Dark id=moon-icon src=https://unknownue.github.io/icons/moon.svg> </a><script>updateItemToggleTheme()</script></nav></header><div class=pull-request-page><article class=md-content-page style=display:none></article><div class=back-link><a href=/pull_request/bevy/2026-01/>← Back to Pull Requests</a></div><div class=pr-metadata><span class=pr-date>2026-01-05</span><div class=language-switcher><span class="lang-link active" data-lang=en>English</span> / <a class=lang-link data-lang=zh-cn href=/pull_request/bevy/2026-01/pr-22314-zh-cn-20260105>中文</a></div></div><div class=pr-content><h1 id=title-parallel-gpu-buffer-writes>Title: Parallel GPU buffer writes</h1><h2 id=basic-information>Basic Information</h2><ul><li><strong>Title</strong>: Parallel GPU buffer writes<li><strong>PR Link</strong>: https://github.com/bevyengine/bevy/pull/22314<li><strong>Author</strong>: aevyrie<li><strong>Status</strong>: MERGED<li><strong>Labels</strong>: A-Rendering, C-Performance, S-Ready-For-Final-Review<li><strong>Created</strong>: 2025-12-30T05:22:13Z<li><strong>Merged</strong>: 2026-01-05T02:56:13Z<li><strong>Merged By</strong>: alice-i-cecile</ul><h2 id=description-translation>Description Translation</h2><h1 id=objective>Objective</h1><ul><li>After a series of optimizations making render and postupdate more parallel, <code>write_batched_instance_buffers</code> was regularly one of the largest spans with very low thread use, sitting at 4ms in 1 4ms frame. This makes it an ideal target to improve throughput. Note this screenshot doesn’t include some visibility system optimizations:</ul><img alt=image height=718 src=https://github.com/user-attachments/assets/bbd6762b-5145-48f8-a427-5da3cb11a04a width=650><h2 id=solution>Solution</h2><ul><li>Spawn tasks for writing buffers to the GPU. This is especially helpful for <code>current_input_buffer</code> and <code>previous_input_buffer</code>, which take about the same time and are the longest buffer writes - moving these to tasks effectively halves the time spent in the system.</ul><img alt=image height=251 src=https://github.com/user-attachments/assets/0a086e7a-1d3c-4c17-9d66-eff94196943d width=588><ul><li>In the 250k bevymark_3d stress test, this saves 1.7ms in the system, and 2.8ms in frame time</ul><p>frametime</p><img alt=image height=376 src=https://github.com/user-attachments/assets/a4c106ac-7668-4f8a-970f-71cbb8be851c width=620><p>system</p><img alt=image height=744 src=https://github.com/user-attachments/assets/5c42227d-8ee5-4b84-bc1a-c04768356255 width=1384><h2 id=testing>Testing</h2><ul><li><code>cargo rer bevymark_3d --features=debug,trace_tracy -- --benchmark --waves 250 --per-wave 1000</code></ul><h2 id=the-story-of-this-pull-request>The Story of This Pull Request</h2><p>This pull request addresses a performance bottleneck in Bevy’s rendering pipeline. After previous optimizations had parallelized other parts of the render and postupdate systems, the <code>write_batched_instance_buffers</code> function emerged as a significant performance issue. Tracy profiling showed this function taking approximately 4ms per frame with very low thread utilization, making it a prime candidate for optimization.<p>The core problem was sequential GPU buffer writes. The original implementation performed all buffer write operations one after another, which failed to leverage available CPU parallelism. This was particularly noticeable for two large buffers: <code>current_input_buffer</code> and <code>previous_input_buffer</code>, which took roughly equal time to write. Since these operations were independent and could execute concurrently, the sequential execution was wasting potential performance gains.<p>The solution implements parallel GPU buffer writes using Bevy’s task system. The key insight was that writing different buffers to the GPU are independent operations that can safely run in parallel. By spawning these operations as separate tasks, the system can overlap the work and better utilize available CPU cores.<p>The implementation approach used Bevy’s <code>ComputeTaskPool</code> to create a scope for parallel execution. Within this scope, individual buffer write operations are spawned as async tasks. This allows the system to execute multiple buffer writes simultaneously, reducing the overall time spent in the function.<p>For <code>write_batched_instance_buffers</code>, the implementation creates tasks for:<ol><li>Writing the current input buffer<li>Writing the previous input buffer<li>Writing phase instance buffers for each render phase<li>Writing work item buffers for each render phase</ol><p>Similarly, <code>write_indirect_parameters_buffers</code> was refactored to parallelize writes of indexed and non-indexed buffer components. Each buffer component (data, CPU metadata, GPU metadata, batch sets) gets its own task, allowing for parallel execution across all render phases.<p>The implementation includes tracing spans for each task to maintain profiling visibility. This was important for verifying the parallelization worked correctly and for future performance analysis.<p>The performance impact was significant. In the 250k bevymark_3d stress test, this optimization saved 1.7ms in the system execution time and 2.8ms in overall frame time. The parallel execution effectively halved the time spent writing the two largest buffers by allowing them to write concurrently.<p>This optimization follows a pattern seen in high-performance rendering engines: parallelizing independent GPU operations to hide latency and better utilize multi-core CPUs. The approach is particularly effective because GPU buffer writes often involve memory transfers that can be CPU-bound, making parallel execution beneficial even when the GPU itself might be busy with other work.<p>One important implementation detail is the use of <code>&*render_device</code> and <code>&*render_queue</code> to create references that can be moved into the async tasks. This avoids borrowing issues and ensures each task has the necessary resources to perform the write operations.<p>The changes maintain the same safety guarantees as the original code. Each buffer write operation remains independent, and the task scope ensures all writes complete before the function returns. This preserves the existing synchronization behavior while improving performance through parallel execution.<p>This optimization demonstrates an important principle in game engine development: after optimizing the high-level algorithms, it’s often necessary to look at low-level operations like memory transfers for further performance gains. The parallelization approach used here can serve as a template for optimizing other sequential GPU operations in the rendering pipeline.<h2 id=visual-representation>Visual Representation</h2><pre class=language-mermaid data-lang=mermaid style=color:#61676c;background-color:#fafafa><code class=language-mermaid data-lang=mermaid><span>graph TD
</span><span>    A[write_batched_instance_buffers] --> B[ComputeTaskPool scope]
</span><span>    B --> C[Task: current_input_buffer write]
</span><span>    B --> D[Task: previous_input_buffer write]
</span><span>    B --> E[Loop: phase_instance_buffers]
</span><span>    E --> F[Task: phase buffers write]
</span><span>    E --> G[Loop: work_item_buffers]
</span><span>    G --> H[Task: work_item buffers write]
</span><span>    
</span><span>    I[write_indirect_parameters_buffers] --> J[ComputeTaskPool scope]
</span><span>    J --> K[Loop: indirect_parameters_buffers]
</span><span>    K --> L[Task: indexed data write]
</span><span>    K --> M[Task: non_indexed data write]
</span><span>    K --> N[Task: indexed CPU metadata write]
</span><span>    K --> O[Task: non_indexed CPU metadata write]
</span><span>    K --> P[Task: indexed GPU metadata write]
</span><span>    K --> Q[Task: non_indexed GPU metadata write]
</span><span>    K --> R[Task: indexed batch_sets write]
</span><span>    K --> S[Task: non_indexed batch_sets write]
</span></code></pre><h2 id=key-files-changed>Key Files Changed</h2><h3 id=crates-bevy-render-src-batching-gpu-preprocessing-rs-129-82><code>crates/bevy_render/src/batching/gpu_preprocessing.rs</code> (+129/-82)</h3><p>This file contains the main changes that parallelize GPU buffer writes. The modifications transform two functions from sequential execution to parallel execution using Bevy’s task system.<p><strong>Before - Sequential execution in <code>write_batched_instance_buffers</code>:</strong><pre class=language-rust data-lang=rust style=color:#61676c;background-color:#fafafa><code class=language-rust data-lang=rust><span>current_input_buffer
</span><span>    </span><span style=color:#ed9366>.</span><span>buffer
</span><span>    </span><span style=color:#ed9366>.</span><span style=color:#f07171>write_buffer</span><span>(</span><span style=color:#ed9366>&</span><span>render_device</span><span style=color:#61676ccc>, </span><span style=color:#ed9366>&</span><span>render_queue)</span><span style=color:#61676ccc>;
</span><span>previous_input_buffer
</span><span>    </span><span style=color:#ed9366>.</span><span>buffer
</span><span>    </span><span style=color:#ed9366>.</span><span style=color:#f07171>write_buffer</span><span>(</span><span style=color:#ed9366>&</span><span>render_device</span><span style=color:#61676ccc>, </span><span style=color:#ed9366>&</span><span>render_queue)</span><span style=color:#61676ccc>;
</span><span>
</span><span style=color:#fa6e32>for</span><span> phase_instance_buffers </span><span style=color:#ed9366>in</span><span> phase_instance_buffers</span><span style=color:#ed9366>.</span><span style=color:#f07171>values_mut</span><span>() {
</span><span>    </span><span style=color:#abb0b6;font-style:italic>// ... sequential writes for each phase
</span><span>    data_buffer</span><span style=color:#ed9366>.</span><span style=color:#f07171>write_buffer</span><span>(</span><span style=color:#ed9366>&</span><span>render_device)</span><span style=color:#61676ccc>;
</span><span>    late_indexed_indirect_parameters_buffer</span><span style=color:#ed9366>.</span><span style=color:#f07171>write_buffer</span><span>(</span><span style=color:#ed9366>&</span><span>render_device</span><span style=color:#61676ccc>, </span><span style=color:#ed9366>&</span><span>render_queue)</span><span style=color:#61676ccc>;
</span><span>    
</span><span>    </span><span style=color:#fa6e32>for</span><span> phase_work_item_buffers </span><span style=color:#ed9366>in</span><span> work_item_buffers</span><span style=color:#ed9366>.</span><span style=color:#f07171>values_mut</span><span>() {
</span><span>        </span><span style=color:#abb0b6;font-style:italic>// ... sequential writes for each work item buffer
</span><span>        </span><span style=color:#fa6e32>match </span><span style=color:#ed9366>*</span><span>phase_work_item_buffers {
</span><span>            PreprocessWorkItemBuffers</span><span style=color:#ed9366>::</span><span>Direct(</span><span style=color:#fa6e32>ref mut</span><span> buffer_vec) </span><span style=color:#ed9366>=> </span><span>{
</span><span>                buffer_vec</span><span style=color:#ed9366>.</span><span style=color:#f07171>write_buffer</span><span>(</span><span style=color:#ed9366>&</span><span>render_device</span><span style=color:#61676ccc>, </span><span style=color:#ed9366>&</span><span>render_queue)</span><span style=color:#61676ccc>;
</span><span>            }
</span><span>            </span><span style=color:#abb0b6;font-style:italic>// ... other cases
</span><span>        }
</span><span>    }
</span><span>}
</span></code></pre><p><strong>After - Parallel execution using tasks:</strong><pre class=language-rust data-lang=rust style=color:#61676c;background-color:#fafafa><code class=language-rust data-lang=rust><span>ComputeTaskPool</span><span style=color:#ed9366>::</span><span>get()</span><span style=color:#ed9366>.</span><span style=color:#f07171>scope</span><span>(|</span><span style=color:#ff8f40>scope</span><span>| {
</span><span>    scope</span><span style=color:#ed9366>.</span><span style=color:#f07171>spawn</span><span>(async {
</span><span>        </span><span style=color:#fa6e32>let</span><span> _span </span><span style=color:#ed9366>= </span><span>tracing</span><span style=color:#ed9366>::</span><span>info_span</span><span style=color:#ed9366>!</span><span>(</span><span style=color:#86b300>"write_current_input_buffers"</span><span>)</span><span style=color:#ed9366>.</span><span style=color:#f07171>entered</span><span>()</span><span style=color:#61676ccc>;
</span><span>        current_input_buffer
</span><span>            </span><span style=color:#ed9366>.</span><span>buffer
</span><span>            </span><span style=color:#ed9366>.</span><span style=color:#f07171>write_buffer</span><span>(render_device</span><span style=color:#61676ccc>,</span><span> render_queue)</span><span style=color:#61676ccc>;
</span><span>    })</span><span style=color:#61676ccc>;
</span><span>    scope</span><span style=color:#ed9366>.</span><span style=color:#f07171>spawn</span><span>(async {
</span><span>        </span><span style=color:#fa6e32>let</span><span> _span </span><span style=color:#ed9366>= </span><span>tracing</span><span style=color:#ed9366>::</span><span>info_span</span><span style=color:#ed9366>!</span><span>(</span><span style=color:#86b300>"write_previous_input_buffers"</span><span>)</span><span style=color:#ed9366>.</span><span style=color:#f07171>entered</span><span>()</span><span style=color:#61676ccc>;
</span><span>        previous_input_buffer
</span><span>            </span><span style=color:#ed9366>.</span><span>buffer
</span><span>            </span><span style=color:#ed9366>.</span><span style=color:#f07171>write_buffer</span><span>(render_device</span><span style=color:#61676ccc>,</span><span> render_queue)</span><span style=color:#61676ccc>;
</span><span>    })</span><span style=color:#61676ccc>;
</span><span>
</span><span>    </span><span style=color:#fa6e32>for</span><span> phase_instance_buffers </span><span style=color:#ed9366>in</span><span> phase_instance_buffers</span><span style=color:#ed9366>.</span><span style=color:#f07171>values_mut</span><span>() {
</span><span>        </span><span style=color:#abb0b6;font-style:italic>// ... spawn tasks for phase buffers
</span><span>        scope</span><span style=color:#ed9366>.</span><span style=color:#f07171>spawn</span><span>(async {
</span><span>            </span><span style=color:#fa6e32>let</span><span> _span </span><span style=color:#ed9366>= </span><span>tracing</span><span style=color:#ed9366>::</span><span>info_span</span><span style=color:#ed9366>!</span><span>(</span><span style=color:#86b300>"write_phase_instance_buffers"</span><span>)</span><span style=color:#ed9366>.</span><span style=color:#f07171>entered</span><span>()</span><span style=color:#61676ccc>;
</span><span>            data_buffer</span><span style=color:#ed9366>.</span><span style=color:#f07171>write_buffer</span><span>(render_device)</span><span style=color:#61676ccc>;
</span><span>            </span><span style=color:#abb0b6;font-style:italic>// ... other buffer writes
</span><span>        })</span><span style=color:#61676ccc>;
</span><span>        
</span><span>        </span><span style=color:#fa6e32>for</span><span> phase_work_item_buffers </span><span style=color:#ed9366>in</span><span> work_item_buffers</span><span style=color:#ed9366>.</span><span style=color:#f07171>values_mut</span><span>() {
</span><span>            scope</span><span style=color:#ed9366>.</span><span style=color:#f07171>spawn</span><span>(async {
</span><span>                </span><span style=color:#fa6e32>let</span><span> _span </span><span style=color:#ed9366>= </span><span>tracing</span><span style=color:#ed9366>::</span><span>info_span</span><span style=color:#ed9366>!</span><span>(</span><span style=color:#86b300>"write_work_item_buffers"</span><span>)</span><span style=color:#ed9366>.</span><span style=color:#f07171>entered</span><span>()</span><span style=color:#61676ccc>;
</span><span>                </span><span style=color:#fa6e32>match </span><span style=color:#ed9366>*</span><span>phase_work_item_buffers {
</span><span>                    PreprocessWorkItemBuffers</span><span style=color:#ed9366>::</span><span>Direct(</span><span style=color:#fa6e32>ref mut</span><span> buffer_vec) </span><span style=color:#ed9366>=> </span><span>{
</span><span>                        buffer_vec</span><span style=color:#ed9366>.</span><span style=color:#f07171>write_buffer</span><span>(render_device</span><span style=color:#61676ccc>,</span><span> render_queue)</span><span style=color:#61676ccc>;
</span><span>                    }
</span><span>                    </span><span style=color:#abb0b6;font-style:italic>// ... other cases
</span><span>                }
</span><span>            })</span><span style=color:#61676ccc>;
</span><span>        }
</span><span>    }
</span><span>})</span><span style=color:#61676ccc>;
</span></code></pre><p>Similar changes were made to <code>write_indirect_parameters_buffers</code>, where each buffer component write was moved into its own task within a <code>ComputeTaskPool</code> scope.<h2 id=further-reading>Further Reading</h2><ol><li><p><strong>Bevy Task System</strong>: Understanding Bevy’s task system and <code>ComputeTaskPool</code> is essential for similar optimizations. The Bevy documentation on parallel programming patterns provides relevant context.</p><li><p><strong>GPU Buffer Management</strong>: For background on GPU buffer operations and why they benefit from parallelization, resources on modern graphics API usage (Vulkan/DirectX 12/Metal) explain the CPU-GPU interaction patterns.</p><li><p><strong>Tracy Profiler</strong>: The profiling screenshots in the PR description come from Tracy, a real-time telemetry profiler. Learning to use profiling tools effectively is crucial for identifying performance bottlenecks like this one.</p><li><p><strong>Amdahl’s Law</strong>: This optimization demonstrates Amdahl’s Law in practice - after parallelizing other parts of the system, the sequential buffer writes became the limiting factor for overall performance improvement.</p><li><p><strong>Async Rust Patterns</strong>: The implementation uses async/await patterns within the task system. Resources on Rust’s async programming model help understand the scoping and lifetime management techniques used in this PR.</p></ol></div><div data-is-md-page=true data-patch-exists=true data-patch-path=/pull_request/bevy/2026-01/pr_22314.patch id=patch-info style=display:none></div><div class=bottom-spacer></div></div></div>