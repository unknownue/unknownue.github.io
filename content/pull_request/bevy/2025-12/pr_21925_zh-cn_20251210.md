+++
title = "#21925 Avoid reading the entire asset into memory during asset processing."
date = "2025-12-10T00:00:00"
draft = false
template = "pull_request_page.html"
in_search_index = false

[extra]
current_language = "zh-cn"
available_languages = {"en" = { name = "English", url = "/pull_request/bevy/2025-12/pr-21925-en-20251210" }, "zh-cn" = { name = "中文", url = "/pull_request/bevy/2025-12/pr-21925-zh-cn-20251210" }}
labels = ["C-Bug", "A-Assets", "C-Performance", "D-Straightforward"]
+++

# Title

## Basic Information
- **Title**: Avoid reading the entire asset into memory during asset processing.
- **PR Link**: https://github.com/bevyengine/bevy/pull/21925
- **Author**: andriyDev
- **Status**: MERGED
- **Labels**: C-Bug, A-Assets, C-Performance, S-Ready-For-Final-Review, D-Straightforward
- **Created**: 2025-11-24T02:40:44Z
- **Merged**: 2025-12-10T00:19:59Z
- **Merged By**: alice-i-cecile

## Description Translation
**目标**
- 在处理资产时，我们首先将整个资产读入内存，然后基于内存中的表示来处理资产。这意味着大型资产可能无法装入内存，从而导致更严重的问题（例如，切换到缓慢的虚拟内存）。

**解决方案**
- 在处理过程中分两次读取资产：1）第一次用于确定资产哈希值，2）第二次用于实际处理资产。

这意味着处理代码本身在任何时候都不需要将整个资产读入内存，从而我们现在可以处理更大的资产。

然而，这存在一些风险。无法分块读取资产的资产源（即需要将整个资产读入内存的资产源）现在必须读取两次（虽然不是同时进行）。这类资产源的一个例子是默认的 Wasm 源或 HTTP 资产源。实际上，我认为这不是一个大问题——处理很可能发生在本地资产上——用户不太可能希望多次从 HTTP 资产源下载大型资产（这在你每次启动应用程序时都需要发生，即使忽略此 PR）。

**测试**
- 所有的处理测试仍然通过。

## The Story of This Pull Request

这个PR解决了一个在Bevy资产处理流程中存在的性能和内存使用问题。在修改之前，资产处理器的通用流程是：首先从资产源（Asset Source）读取整个资产文件到一个字节数组（`Vec<u8>`）中。然后，这个完整的字节数组会同时被用于计算资产的哈希（用于版本控制和缓存）以及传递给`Process` trait的实现进行实际处理。

当处理大型资产文件（如高分辨率纹理或复杂的3D模型）时，这种方法存在明显的缺陷。将整个文件加载到内存可能会导致巨大的内存压力，甚至触发操作系统使用虚拟内存（Virtual Memory），从而显著降低处理速度。

为了解决这个问题，PR引入了一个新的策略：将计算哈希与实际处理资产解耦，并采用流式读取（Streaming Read）的方式。具体实现上，`get_asset_hash`函数被修改为异步函数，它接受一个实现了`Reader` trait的引用，然后分块读取数据（块大小为`blake3::CHUNK_LEN`）并更新哈希计算器。这样，在计算哈希时就不需要一次性将资产内容加载到内存中。

资产处理器（`AssetProcessor::process`）的逻辑也随之调整。现在的流程是：
1.  创建一个临时的`reader_for_hash`，用于计算资产哈希。计算完成后，此读取器被丢弃。
2.  再创建一个新的`reader_for_process`，用于实际的处理阶段。
3.  在处理上下文（`ProcessContext`）中，不再持有对`&[u8]`的引用，而是持有一个`Box<dyn Reader>`。相应地，`ProcessContext::asset_bytes()`方法被替换为`ProcessContext::asset_reader()`，返回一个`Reader`的引用。

这个变化带来两个主要影响：
-   **内存优势**：处理代码现在可以通过`asset_reader()`按需流式读取数据。如果某个资产处理器（例如图像处理器）本身实现了流式处理，它就不再需要将整个文件加载到内存中。这极大地降低了大文件处理的内存占用。
-   **I/O权衡**：对于资产源，这个策略意味着资产文件被读取了两次。对于本地文件系统，这通常是可以接受的，因为磁盘I/O相对较快。然而，对于像HTTP这样的远程资产源，这可能意味着需要下载文件两次，这是一个显著的性能开销。PR的作者也明确指出了这个权衡，并认为在实际使用中，资产处理主要发生在本地开发或构建时，远程处理的场景较少，因此这个代价是值得的。作者还提到，未来可以通过询问资产源是否希望避免重复读取来进一步优化。

从架构角度看，这个改动推动了资产处理逻辑向更现代的流式处理模型演进。它使得`Process` trait的实现者可以更灵活地处理数据，也为未来处理超大型资产（如视频流）奠定了基础。同时，为了向后兼容，新添加的迁移指南详细说明了如何将旧的、依赖于完整字节数组的`Process`实现，迁移到使用新的`Reader`接口。

## Visual Representation

```mermaid
graph TD
    subgraph "Old Process Flow"
        A1[Asset Source] -->|read entire file| B1[Asset Bytes in Memory Vec<u8>]
        B1 --> C1[Compute Hash]
        B1 --> D1[Process Asset]
    end

    subgraph "New Process Flow"
        A2[Asset Source] -->|create Reader| B2[Reader for Hash]
        B2 --> C2[Compute Hash (Streaming)]
        A2 -->|create another Reader| D2[Reader for Process]
        D2 --> E2[Process Asset (Streaming via ProcessContext)]
    end

    C1 & C2 --> F[Generate Asset Hash]
    D1 & E2 --> G[Output Processed Asset]
```

## Key Files Changed

1.  **`crates/bevy_asset/src/processor/mod.rs` (+31/-22)**
    - 这是主要的逻辑修改文件。修改移除了将整个资产读入`asset_bytes: Vec<u8>`的步骤，并改为分两次创建读取器（Reader）。
    - 关键代码段显示了新的控制流，包括注释，解释了工程权衡：
        ```rust
        let new_hash = {
            // Create a reader just for computing the hash. Keep this scoped here so that we drop it
            // as soon as the hash is computed.
            let mut reader_for_hash = reader.read(path).await.map_err(reader_err)?;
            get_asset_hash(&meta_bytes, &mut reader_for_hash)
                .await
                .map_err(reader_err)?
        };
        ...
        // Create a reader just for the actual process. Note: this means that we're performing two
        // reads for the same file (but we avoid having to load the whole file into memory). ...
        let mut reader_for_process = reader.read(path).await.map_err(reader_err)?;
        ```
    - 当没有自定义处理器（`processor`）时，代码也从写入内存字节改为直接进行流式复制（`futures_lite::io::copy`），进一步避免了不必要的内存分配。

2.  **`crates/bevy_asset/src/processor/process.rs` (+15/-9)**
    - 修改了`ProcessContext`的结构，将`asset_bytes: &'a [u8]`字段替换为`reader: Box<dyn Reader + 'a>`。
    - 提供了新的`asset_reader()`方法以替代旧的`asset_bytes()`。
    - `ProcessContext::new`的签名和内部逻辑相应更新，以接受一个`Reader`。
    - `Process::process`的实现现在可以通过`context.asset_reader()`获得一个流式读取器，从而按需处理数据。

3.  **`crates/bevy_asset/src/meta.rs` (+20/-6)**
    - 核心修改是将`get_asset_hash`函数改为异步，并让其接受一个`Reader`而非字节切片。
    - 新实现使用固定大小的缓冲区进行循环读取，实现了流式哈希计算：
        ```rust
        pub(crate) async fn get_asset_hash(
            meta_bytes: &[u8],
            asset_reader: &mut impl Reader,
        ) -> Result<AssetHash, AssetReaderError> {
            let mut hasher = blake3::Hasher::new();
            hasher.update(meta_bytes);
            let mut buffer = [0; blake3::CHUNK_LEN];
            loop {
                let bytes_read = asset_reader.read(&mut buffer).await?;
                hasher.update(&buffer[..bytes_read]);
                if bytes_read < buffer.len() {
                    break;
                }
            }
            Ok(*hasher.finalize().as_bytes())
        }
        ```
    - 这使得计算哈希的过程同样不依赖完整的内存数据。

4.  **`release-content/migration-guides/process_trait_changes.md` (+30/-0)**
    - 这是一个新增的迁移指南文件，为`Process` trait的用户提供了清晰的升级路径。
    - 它展示了如何将依赖`asset_bytes()`的旧代码迁移到使用新的`asset_reader()`接口。如果处理器确实需要完整的字节数据，指南展示了如何通过`read_to_end`方法手动读取，这保持了向后兼容性，同时将内存分配的决定权交给了处理器实现者。

## Further Reading
- **Bevy Asset System Book**: 可以查阅Bevy官方文档中关于资产系统的部分，以理解资产加载和处理的完整流程。
- **Streaming vs Buffered I/O**: 了解流式输入输出（Streaming I/O）与缓冲式I/O（Buffered I/O）的区别和各自的适用场景，有助于理解此PR优化的核心思想。
- **`async`/`await` in Rust**: 此PR中多处函数改为`async`，熟悉Rust的异步编程模型对理解代码执行流程至关重要。
- **The `blake3` Hash Function**: 了解BLAKE3哈希算法的特性，特别是其支持流式更新的能力，这为本次优化提供了基础。